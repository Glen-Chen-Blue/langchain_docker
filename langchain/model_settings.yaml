# 模型配置项

# 默认选用的 LLM 名称
DEFAULT_LLM_MODEL: llama3.1
DEFAULT_EMBEDDING_MODEL: mxbai-embed-large

# AgentLM模型的名称 (可以不指定，指定之后就锁定进入Agent之后的Chain的模型，不指定就是 DEFAULT_LLM_MODEL)
Agent_MODEL: ""
HISTORY_LEN: 3
MAX_TOKENS:

# LLM通用对话参数
TEMPERATURE: 0.3

# 支持的Agent模型
SUPPORT_AGENT_MODELS:
  - chatglm3-6b

LLM_MODEL_CONFIG:
  preprocess_model:
    model: ""
    temperature: 0.05
    max_tokens: 4096
    history_len: 10
    prompt_name: default
    callbacks: false
  llm_model:
    model: ""
    temperature: 0.3
    max_tokens: 4096
    history_len: 10
    prompt_name: default
    callbacks: true
  action_model:
    model: ""
    temperature: 0.01
    max_tokens: 4096
    history_len: 10
    prompt_name: ChatGLM3
    callbacks: true
  postprocess_model:
    model: ""
    temperature: 0.01
    max_tokens: 4096
    history_len: 10
    prompt_name: default
    callbacks: true
  image_model:
    model: sd-turbo
    size: 256*256

MODEL_PLATFORMS:
  - platform_name: ollama
    platform_type: ollama
    api_base_url: http://127.0.0.1:11434/v1
    api_key: EMPTY
    api_proxy: ""
    api_concurrencies: 5
    auto_detect_model: false
    llm_models:
      - llama3
      - llama3.1
      - llama3.2:1b
      - llama3.2:3b
    embed_models:
      - mxbai-embed-large
    text2image_models: []
    image2text_models: []
    rerank_models: []
    speech2text_models: []
    text2speech_models: []